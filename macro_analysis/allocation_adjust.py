# macro_analysis/allocation_adjust.py

import numpy as np
from scipy.stats import zscore
from macro_data import fetch_macro_data

# Ray Dalio baseline weights
BASELINE_WEIGHTS = {
    "equities": 30,      # è‚¡ç¥¨ç±»èµ„äº§
    "bonds_mid": 15,     # ä¸­æœŸå€ºåˆ¸ï¼Œå¦‚2-5å¹´å›½å€ºæˆ–ä¿¡ç”¨å€º
    "bonds_long": 40,    # é•¿æœŸå€ºåˆ¸ï¼Œå¦‚10å¹´åŠä»¥ä¸Šå›½å€º
    "gold": 7.5,         # é»„é‡‘èµ„äº§
    "commodities": 7.5   # å¤§å®—å•†å“ï¼ˆå¦‚åŸæ²¹ã€é“œç­‰ï¼‰
}

# å®šä¹‰æ¯ç±»èµ„äº§çš„å…ˆéªŒï¼ˆå‡å€¼ï¼Œæ ‡å‡†å·®ï¼‰
PRIOR_DISTRIBUTIONS = {
    "equities": (30, 5),
    "bonds_mid": (15, 3),
    "bonds_long": (40, 5),
    "gold": (7.5, 2),
    "commodities": (7.5, 2)
}

# Z-scoreè½¬æƒé‡è°ƒæ•´ï¼ˆé™åˆ¶åœ¨Â±3%å†…ï¼‰
def z_to_adjustment(z, scale=1.5, max_adjust=3):
    score = z * scale
    return max(-max_adjust, min(max_adjust, score))

# è®¡ç®—z-scoreå¹¶åº”ç”¨è°ƒæ•´é€»è¾‘
def infer_observed_means(macro_data):
    observed = BASELINE_WEIGHTS.copy()

    def calc_z(df):
        series = df["data"]["value"]
        return ((series - series.mean()) / series.std()).iloc[-1]

    # ğŸŸ¡ CPIæ€»é€šèƒ€æŒ‡æ ‡ï¼Œé«˜é€šèƒ€ â†’ å¢åŠ é»„é‡‘/å•†å“ï¼Œå‡å°‘é•¿æœŸå€º
    if "CPIAUCSL" in macro_data:
        z = calc_z(macro_data["CPIAUCSL"])
        delta = z_to_adjustment(z)
        observed["gold"] += delta
        observed["commodities"] += delta
        observed["bonds_long"] -= delta

    # ğŸŸ¡ PCEæ ¸å¿ƒé€šèƒ€ï¼Œåæ˜ ä»·æ ¼ä¸Šå‡ç²˜æ€§ï¼Œåä¿å®ˆåœ°å¢åŠ é»„é‡‘
    if "PCEPI" in macro_data:
        z = calc_z(macro_data["PCEPI"])
        delta = z_to_adjustment(z)
        observed["gold"] += delta * 0.7

    # ğŸŸ¡ æ ¸å¿ƒCPIï¼šå‰”é™¤æ³¢åŠ¨é¡¹çš„ä»·æ ¼æŒ‡æ ‡ï¼Œé€‚åº¦åŠ é»„é‡‘
    if "CPILFESL" in macro_data:
        z = calc_z(macro_data["CPILFESL"])
        delta = z_to_adjustment(z)
        observed["gold"] += delta * 0.5

    # ğŸ”µ GS10ï¼š10å¹´å›½å€ºåˆ©ç‡ä¸Šå‡ â†’ å‡é…é•¿æœŸå€º
    if "GS10" in macro_data:
        z = calc_z(macro_data["GS10"])
        delta = z_to_adjustment(z)
        observed["bonds_long"] -= delta

    # ğŸ”µ GS2ï¼š2å¹´çŸ­å€ºåˆ©ç‡ä¸Šå‡ â†’ å¢é…ä¸­æœŸå€º
    if "GS2" in macro_data:
        z = calc_z(macro_data["GS2"])
        delta = z_to_adjustment(z)
        observed["bonds_mid"] += delta

    # ğŸ”µ è”é‚¦åŸºé‡‘åˆ©ç‡ï¼šä»£è¡¨æ”¿ç­–åˆ©ç‡ï¼Œå‡é«˜æ—¶å¢é…çŸ­å€º
    if "FEDFUNDS" in macro_data:
        z = calc_z(macro_data["FEDFUNDS"])
        delta = z_to_adjustment(z)
        observed["bonds_mid"] += delta

    # ğŸŸ¢ GDPå¢é•¿å¼º â†’ å¢è‚¡å‡å€ºï¼›è¡°é€€ â†’ å‡è‚¡åŠ å€º
    if "GDP" in macro_data:
        z = calc_z(macro_data["GDP"])
        delta = z_to_adjustment(z)
        observed["equities"] += delta
        observed["bonds_long"] -= delta * 0.5

    # ğŸŸ¢ PAYEMSï¼šéå†œå°±ä¸šäººæ•°å¢é•¿ â†’ å¢è‚¡
    if "PAYEMS" in macro_data:
        z = calc_z(macro_data["PAYEMS"])
        delta = z_to_adjustment(z)
        observed["equities"] += delta

    # ğŸŸ¢ UNRATEï¼šå¤±ä¸šç‡å‡é«˜ â†’ å‡è‚¡åŠ å€º
    if "UNRATE" in macro_data:
        z = calc_z(macro_data["UNRATE"])
        delta = z_to_adjustment(z)
        observed["equities"] -= delta
        observed["bonds_long"] += delta

    # ğŸŸ¢ INDPROï¼šå·¥ä¸šäº§å‡ºæ”¹å–„ â†’ å¢è‚¡
    if "INDPRO" in macro_data:
        z = calc_z(macro_data["INDPRO"])
        delta = z_to_adjustment(z)
        observed["equities"] += delta

    # ğŸ”´ UMCSENTï¼šæ¶ˆè´¹è€…ä¿¡å¿ƒä¸Šå‡ â†’ å¢é…è‚¡ç¥¨
    if "UMCSENT" in macro_data:
        z = calc_z(macro_data["UMCSENT"])
        delta = z_to_adjustment(z)
        observed["equities"] += delta

    # ğŸ”´ M2è´§å¸æ‰©å¼  â†’ è‚¡/å•†å“å—ç›Šï¼›ç´§ç¼© â†’ å‡ä»“
    if "M2SL" in macro_data:
        z = calc_z(macro_data["M2SL"])
        delta = z_to_adjustment(z)
        observed["equities"] += delta
        observed["commodities"] += delta

    # ğŸ”´ VIXä¸Šå‡ â†’ ææ…Œæƒ…ç»ª â†‘ï¼Œå‡è‚¡åŠ å€ºé¿é™©
    if "VIXCLS" in macro_data:
        z = calc_z(macro_data["VIXCLS"])
        delta = z_to_adjustment(z)
        observed["equities"] -= delta
        observed["bonds_mid"] += delta

    return observed

# è´å¶æ–¯æ›´æ–°å‡½æ•°
def bayesian_update(prior_mu, prior_sigma, obs_mu, obs_sigma):
    post_mean = (prior_mu / prior_sigma**2 + obs_mu / obs_sigma**2) / (1 / prior_sigma**2 + 1 / obs_sigma**2)
    post_std = np.sqrt(1 / (1 / prior_sigma**2 + 1 / obs_sigma**2))
    return round(post_mean, 2), round(post_std, 2)

def adjust_allocation(macro_data):
    obs_means = infer_observed_means(macro_data)
    OBS_SIGMA = 3

    updated_weights = {}
    for asset in BASELINE_WEIGHTS:
        mu_prior, sigma_prior = PRIOR_DISTRIBUTIONS[asset]
        mu_obs = obs_means[asset]
        mu_post, sigma_post = bayesian_update(mu_prior, sigma_prior, mu_obs, OBS_SIGMA)
        updated_weights[asset] = mu_post

    total = sum(updated_weights.values())
    for asset in updated_weights:
        updated_weights[asset] = round(updated_weights[asset] * 100 / total, 2)

    return updated_weights

if __name__ == "__main__":
    macro_data = fetch_macro_data()
    weights = adjust_allocation(macro_data)
    print("\nğŸ“Š æœ¬å­£åº¦è´å¶æ–¯ + Z-score è°ƒæ•´åçš„èµ„äº§é…ç½®å»ºè®®ï¼š")
    for asset, weight in weights.items():
        print(f"{asset}: {weight}%")